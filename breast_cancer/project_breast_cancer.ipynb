{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP2 - Project\n",
    "## Team:\n",
    "- Bauer Fabian (h12308122)\n",
    "- Bruckner-Hrubesch Sebastian (h)\n",
    "- Rivalta Florian (h12319658)\n",
    "- ZÃ¤hrer Raphael (h12311217)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Creating a spark session\n",
    "- importing all libraries\n",
    "- setting up a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    findspark.init(\"/usr/local/spark/\")\n",
    "\n",
    "    spark = SparkSession.builder \\\n",
    "       .master(\"local\") \\\n",
    "       .appName(\"project_breast_cancer\") \\\n",
    "       .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "       .getOrCreate()\n",
    "\n",
    "    sc = spark.sparkContext\n",
    "    \n",
    "except:\n",
    "    print(\"There was an issue when creating a Spark session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Reading in the CSV and transform to RDD\n",
    "- splitting the \"row-strings\" by comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_file(filename):\n",
    "\n",
    "    try:\n",
    "        rdd = sc.textFile(f\"{filename}\", minPartitions=4)\n",
    "        rdd = rdd.map(lambda line: line.split(\",\"))\n",
    "        return rdd\n",
    "    \n",
    "    except:\n",
    "        print(f\"Unable to read in the file with filePath: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_bc = reading_file(\"breast_cancer_wisconsin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Converting the RDD to a DataFrame\n",
    "- filtering out the first row because it is empty\n",
    "- transforming the columns to the right dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(rdd):\n",
    "    \n",
    "    columns = [\"ID\", \"diagnosis\", \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \n",
    "               \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\", \"concave_points_mean\", \n",
    "               \"symmetry_mean\", \"fractal_dimension_mean\", \"radius_se\", \"texture_se\", \n",
    "               \"perimeter_se\", \"area_se\", \"smoothness_se\", \"compactness_se\", \"concavity_se\", \n",
    "               \"concave_points_se\", \"symmetry_se\", \"fractal_dimension_se\", \"radius_worst\", \n",
    "               \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\", \n",
    "               \"compactness_worst\", \"concavity_worst\", \"concave_points_worst\", \n",
    "               \"symmetry_worst\", \"fractal_dimension_worst\"]\n",
    "    \n",
    "    \n",
    "    rdd_header = rdd.first()\n",
    "    rdd = rdd.filter(lambda x: x != rdd_header)\n",
    "    \n",
    "    df = rdd.map(lambda line: Row(**{columns[i]: line[i] for i in range(len(columns))})).toDF()\n",
    "    \n",
    "    columns_to_cast = columns[2:]\n",
    "    \n",
    "    for col_name in columns_to_cast:\n",
    "        df = df.withColumn(col_name, col(col_name).cast(FloatType()))\n",
    "    \n",
    "    df = df.withColumn(\"ID\", col(\"ID\").cast(IntegerType()))\n",
    "    df = df.withColumn(\"diagnosis\", when(col(\"diagnosis\") == \"M\", 1).otherwise(0).cast(IntegerType()))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- diagnosis: integer (nullable = false)\n",
      " |-- radius_mean: float (nullable = true)\n",
      " |-- texture_mean: float (nullable = true)\n",
      " |-- perimeter_mean: float (nullable = true)\n",
      " |-- area_mean: float (nullable = true)\n",
      " |-- smoothness_mean: float (nullable = true)\n",
      " |-- compactness_mean: float (nullable = true)\n",
      " |-- concavity_mean: float (nullable = true)\n",
      " |-- concave_points_mean: float (nullable = true)\n",
      " |-- symmetry_mean: float (nullable = true)\n",
      " |-- fractal_dimension_mean: float (nullable = true)\n",
      " |-- radius_se: float (nullable = true)\n",
      " |-- texture_se: float (nullable = true)\n",
      " |-- perimeter_se: float (nullable = true)\n",
      " |-- area_se: float (nullable = true)\n",
      " |-- smoothness_se: float (nullable = true)\n",
      " |-- compactness_se: float (nullable = true)\n",
      " |-- concavity_se: float (nullable = true)\n",
      " |-- concave_points_se: float (nullable = true)\n",
      " |-- symmetry_se: float (nullable = true)\n",
      " |-- fractal_dimension_se: float (nullable = true)\n",
      " |-- radius_worst: float (nullable = true)\n",
      " |-- texture_worst: float (nullable = true)\n",
      " |-- perimeter_worst: float (nullable = true)\n",
      " |-- area_worst: float (nullable = true)\n",
      " |-- smoothness_worst: float (nullable = true)\n",
      " |-- compactness_worst: float (nullable = true)\n",
      " |-- concavity_worst: float (nullable = true)\n",
      " |-- concave_points_worst: float (nullable = true)\n",
      " |-- symmetry_worst: float (nullable = true)\n",
      " |-- fractal_dimension_worst: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bc = convert_to_df(rdd_bc)\n",
    "df_bc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 569, Number of columns: 32\n"
     ]
    }
   ],
   "source": [
    "num_rows = df_bc.count()\n",
    "num_columns = len(df_bc.columns)\n",
    "\n",
    "print(f\"Number of rows: {df_bc.count()}, Number of columns: {len(df_bc.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Removing unnecessary columns\n",
    "- removing columns that are not important for our linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_cols(df):\n",
    "    df = df.drop(\"ID\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- diagnosis: integer (nullable = false)\n",
      " |-- radius_mean: float (nullable = true)\n",
      " |-- texture_mean: float (nullable = true)\n",
      " |-- perimeter_mean: float (nullable = true)\n",
      " |-- area_mean: float (nullable = true)\n",
      " |-- smoothness_mean: float (nullable = true)\n",
      " |-- compactness_mean: float (nullable = true)\n",
      " |-- concavity_mean: float (nullable = true)\n",
      " |-- concave_points_mean: float (nullable = true)\n",
      " |-- symmetry_mean: float (nullable = true)\n",
      " |-- fractal_dimension_mean: float (nullable = true)\n",
      " |-- radius_se: float (nullable = true)\n",
      " |-- texture_se: float (nullable = true)\n",
      " |-- perimeter_se: float (nullable = true)\n",
      " |-- area_se: float (nullable = true)\n",
      " |-- smoothness_se: float (nullable = true)\n",
      " |-- compactness_se: float (nullable = true)\n",
      " |-- concavity_se: float (nullable = true)\n",
      " |-- concave_points_se: float (nullable = true)\n",
      " |-- symmetry_se: float (nullable = true)\n",
      " |-- fractal_dimension_se: float (nullable = true)\n",
      " |-- radius_worst: float (nullable = true)\n",
      " |-- texture_worst: float (nullable = true)\n",
      " |-- perimeter_worst: float (nullable = true)\n",
      " |-- area_worst: float (nullable = true)\n",
      " |-- smoothness_worst: float (nullable = true)\n",
      " |-- compactness_worst: float (nullable = true)\n",
      " |-- concavity_worst: float (nullable = true)\n",
      " |-- concave_points_worst: float (nullable = true)\n",
      " |-- symmetry_worst: float (nullable = true)\n",
      " |-- fractal_dimension_worst: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = removing_cols(df_bc)\n",
    "cleaned_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 569, Number of columns: 31\n"
     ]
    }
   ],
   "source": [
    "num_rows = cleaned_df.count()\n",
    "num_columns = len(cleaned_df.columns)\n",
    "\n",
    "print(f\"Number of rows: {cleaned_df.count()}, Number of columns: {len(cleaned_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Check if there are null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis: 0\n",
      "radius_mean: 0\n",
      "texture_mean: 0\n",
      "perimeter_mean: 0\n",
      "area_mean: 0\n",
      "smoothness_mean: 0\n",
      "compactness_mean: 0\n",
      "concavity_mean: 0\n",
      "concave_points_mean: 0\n",
      "symmetry_mean: 0\n",
      "fractal_dimension_mean: 0\n",
      "radius_se: 0\n",
      "texture_se: 0\n",
      "perimeter_se: 0\n",
      "area_se: 0\n",
      "smoothness_se: 0\n",
      "compactness_se: 0\n",
      "concavity_se: 0\n",
      "concave_points_se: 0\n",
      "symmetry_se: 0\n",
      "fractal_dimension_se: 0\n",
      "radius_worst: 0\n",
      "texture_worst: 0\n",
      "perimeter_worst: 0\n",
      "area_worst: 0\n",
      "smoothness_worst: 0\n",
      "compactness_worst: 0\n",
      "concavity_worst: 0\n",
      "concave_points_worst: 0\n",
      "symmetry_worst: 0\n",
      "fractal_dimension_worst: 0\n"
     ]
    }
   ],
   "source": [
    "def check_for_null_values(df):\n",
    "    \n",
    "    null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "    result = null_counts.head()\n",
    "\n",
    "    null_counts_dict = {col_name: result[col_name] for col_name in result.asDict()}\n",
    "\n",
    "    for column, null_count in null_counts_dict.items():\n",
    "        print(f\"{column}: {null_count}\")\n",
    "\n",
    "check_for_null_values(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation results:\n",
      "------------------------------\n",
      "Test AUC: 0.98\n",
      "\n",
      "Accuracy: 0.92\n",
      "Recall: 0.88\n",
      "Precision: 0.91\n",
      "F1-Score: 0.90\n",
      "\n",
      "Mean Squared Error (MSE): 0.08\n",
      "Root Mean Squared Error (RMSE): 0.28\n"
     ]
    }
   ],
   "source": [
    "def evaluate_logistic_regression_model(df):\n",
    "    \n",
    "    feature_columns = [col for col in df.columns if col != 'diagnosis']\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "    lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"diagnosis\")\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, lr])\n",
    "\n",
    "    train_df, test_df = df.randomSplit([0.8, 0.2], seed=1234)\n",
    "    model = pipeline.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    evaluator_auc = BinaryClassificationEvaluator(labelCol=\"diagnosis\", metricName=\"areaUnderROC\")\n",
    "    auc = evaluator_auc.evaluate(predictions)\n",
    "    \n",
    "    tp = predictions.filter((col(\"diagnosis\") == 1) & (col(\"prediction\") == 1)).count()  # True Positives\n",
    "    tn = predictions.filter((col(\"diagnosis\") == 0) & (col(\"prediction\") == 0)).count()  # True Negatives\n",
    "    fp = predictions.filter((col(\"diagnosis\") == 0) & (col(\"prediction\") == 1)).count()  # False Positives\n",
    "    fn = predictions.filter((col(\"diagnosis\") == 1) & (col(\"prediction\") == 0)).count()  # False Negatives\n",
    "    \n",
    "    accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0 \n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    evaluator_mse = RegressionEvaluator(labelCol=\"diagnosis\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "    mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "    evaluator_rmse = RegressionEvaluator(labelCol=\"diagnosis\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "\n",
    "    print(f\"Evalutation results:\\n\"\n",
    "          f\"{30 * '-'}\\n\"\n",
    "          f\"Test AUC: {auc:.2f}\\n\"\n",
    "          f\"\\nAccuracy: {accuracy:.2f}\\n\"\n",
    "          f\"Recall: {recall:.2f}\\n\"\n",
    "          f\"Precision: {precision:.2f}\\n\"\n",
    "          f\"F1-Score: {f1_score:.2f}\\n\"\n",
    "          f\"\\nMean Squared Error (MSE): {mse:.2f}\\n\"\n",
    "          f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "evaluate_logistic_regression_model(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
